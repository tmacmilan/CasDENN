{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation time 220751999\n",
      "the number of time interval: 14\n",
      "time interval: 15768000\n"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/marsjhao/article/details/68490105 https://blog.csdn.net/u014281392/article/details/77103747\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "np.random.seed(355)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dropout, Bidirectional,Activation,Flatten,GRU,LSTM\n",
    "from keras.layers import Dense, Input, TimeDistributed,RepeatVector\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "import math\n",
    "import time\n",
    "import config_APS_2 as cf\n",
    "import six.moves.cPickle as pickle\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 16)\n"
     ]
    }
   ],
   "source": [
    "# 全局变量\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "CELL_SIZE=32\n",
    "OUTPUT_SIZE=20\n",
    "# input image dimensions\n",
    "TIME_STEPS = cf.n_time_interval\n",
    "datasetName =cf.datasetName\n",
    "INPUT_SIZE = len(cf.degree_interval_list)+1\n",
    "input_shape = (TIME_STEPS, INPUT_SIZE) \n",
    "print (input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21015, 14, 16)\n",
      "(4707, 14, 16)\n",
      "(4476, 14, 16)\n",
      "(21015,)\n"
     ]
    }
   ],
   "source": [
    "id_train, x_train, L, y_train, sz_train, time_train, vocabulary_size = pickle.load(open(cf.train_pkl, 'rb'))\n",
    "id_test, x_test, L_test, y_test, sz_test, time_test, _ = pickle.load(open(cf.test_pkl, 'rb'))\n",
    "id_val, x_val, L_val, y_val, sz_val, time_val, _ = pickle.load(open(cf.val_pkl, 'rb'))\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = np.array(x_train[i])\n",
    "for i in range(len(x_val)):\n",
    "    x_val[i] = np.array(x_val[i])\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i] = np.array(x_test[i])\n",
    "x_val = np.array(x_val)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "# x_train = x_train.reshape(x_train.shape[0], TIME_STEPS, INPUT_SIZE, 1)\n",
    "# x_test = x_test.reshape(x_test.shape[0], TIME_STEPS, INPUT_SIZE, 1)\n",
    "# x_val = x_val.reshape(x_val.shape[0], TIME_STEPS, INPUT_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9242036482665004\n",
      "2.86929922371805\n",
      "-0.05490442454845024\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_train))\n",
    "print(np.mean(y_test))\n",
    "print(np.mean(y_test) - np.mean(y_train))\n",
    "# x_train = x_train.resh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 14, 20)            2220      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 14, 20)            2460      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                4496      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 9,193\n",
      "Trainable params: 9,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 380us/step - loss: 1.4336 - mse: 1.4336 - val_loss: 1.2816 - val_mse: 1.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_mse,loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.2778777578896667\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 332us/step - loss: 1.3339 - mse: 1.3339 - val_loss: 1.2965 - val_mse: 1.2965\n",
      "Test score: 1.2845695789943765\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 333us/step - loss: 1.3167 - mse: 1.3167 - val_loss: 1.2796 - val_mse: 1.2796\n",
      "Test score: 1.2797020106450347\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 324us/step - loss: 1.3096 - mse: 1.3096 - val_loss: 1.2932 - val_mse: 1.2932\n",
      "Test score: 1.3017455953839532\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 316us/step - loss: 1.3024 - mse: 1.3024 - val_loss: 1.2972 - val_mse: 1.2972\n",
      "Test score: 1.3104052518567437\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 329us/step - loss: 1.2953 - mse: 1.2953 - val_loss: 1.3622 - val_mse: 1.3622\n",
      "Test score: 1.3360279808511444\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 381us/step - loss: 1.2910 - mse: 1.2910 - val_loss: 1.2722 - val_mse: 1.2722\n",
      "Test score: 1.2637328182356813\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 354us/step - loss: 1.2837 - mse: 1.2837 - val_loss: 1.2913 - val_mse: 1.2913\n",
      "Test score: 1.277345243421157\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 352us/step - loss: 1.2803 - mse: 1.2803 - val_loss: 1.2825 - val_mse: 1.2825\n",
      "Test score: 1.2704810210415987\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 340us/step - loss: 1.2783 - mse: 1.2783 - val_loss: 1.2795 - val_mse: 1.2795\n",
      "Test score: 1.2715468759594486\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 345us/step - loss: 1.2780 - mse: 1.2780 - val_loss: 1.2768 - val_mse: 1.2768\n",
      "Test score: 1.2854515753760822\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 361us/step - loss: 1.2708 - mse: 1.2708 - val_loss: 1.2786 - val_mse: 1.2786\n",
      "Test score: 1.2894241902284722\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 365us/step - loss: 1.2687 - mse: 1.2687 - val_loss: 1.2824 - val_mse: 1.2824\n",
      "Test score: 1.2982374712340463\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 331us/step - loss: 1.2674 - mse: 1.2674 - val_loss: 1.2741 - val_mse: 1.2741\n",
      "Test score: 1.2886341213546844\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 317us/step - loss: 1.2632 - mse: 1.2632 - val_loss: 1.2646 - val_mse: 1.2646\n",
      "Test score: 1.2763953761155877\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 7s 325us/step - loss: 1.2616 - mse: 1.2616 - val_loss: 1.2549 - val_mse: 1.2549\n",
      "Test score: 1.2592867347169434\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 363us/step - loss: 1.2569 - mse: 1.2569 - val_loss: 1.2728 - val_mse: 1.2728\n",
      "Test score: 1.2930848177816043\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 390us/step - loss: 1.2545 - mse: 1.2545 - val_loss: 1.2486 - val_mse: 1.2486\n",
      "Test score: 1.254963419912017\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 9s 406us/step - loss: 1.2537 - mse: 1.2537 - val_loss: 1.2661 - val_mse: 1.2661\n",
      "Test score: 1.2686072642164472\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 380us/step - loss: 1.2487 - mse: 1.2487 - val_loss: 1.2745 - val_mse: 1.2745\n",
      "Test score: 1.2704347146780648\n"
     ]
    }
   ],
   "source": [
    "## LSTM \n",
    "model = Sequential()\n",
    "model.add(GRU(units = OUTPUT_SIZE, activation='tanh', input_shape=input_shape,return_sequences=True))\n",
    "model.add(GRU(units = OUTPUT_SIZE, activation='tanh',return_sequences=True))\n",
    "model.add(Flatten()) #拉成一维数据\n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(1, activation='relu')) #全连接层2\n",
    "# model.add(Dense(1, activation='relu')) #全连接层2\n",
    " \n",
    "#编译模型\n",
    "model.compile(loss='mean_squared_error',optimizer='adadelta',metrics=['mse'])\n",
    "model.summary()  #打印模型\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3,verbose = 1, factor=0.5, min_lr = 0.000000001)\n",
    "#训练模型\n",
    "f = open(datasetName+'result_epoch_rnn.csv','w')\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=1, validation_data=(x_val, y_val), \n",
    "              shuffle=True, verbose=1,callbacks=[learning_rate_reduction])\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    val_score  = model.evaluate(x_val, y_val, verbose=0)\n",
    "    f.write(str(epoch)+',Test score,'+ str(test_score[0])+',Val_score,'+str(val_score[0])+'\\n')\n",
    "    print('Test score:', test_score[0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.1421112669534368\n",
      "Test accuracy: 1.1421111822128296\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_test_pre = model.predict(x_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "f = open(datasetName+'detail_result_rnn_.csv','w')\n",
    "for i in range (len(y_test)):\n",
    "    f.write(str(y_test[i])+','+str(y_test_pre[i][0])+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 12)          0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, None, 32)          4320      \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, None, 16)          2352      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 16)          272       \n",
      "_________________________________________________________________\n",
      "de_gru1 (GRU)                (None, None, 16)          1584      \n",
      "_________________________________________________________________\n",
      "de_gru2 (GRU)                (None, None, 32)          4704      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, None, 12)          396       \n",
      "=================================================================\n",
      "Total params: 13,628\n",
      "Trainable params: 13,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/20\n",
      "2256/2256 [==============================] - 5s 2ms/step - loss: 24.8726 - mean_squared_error: 24.8726 - val_loss: 18.5608 - val_mean_squared_error: 18.5608\n",
      "Epoch 2/20\n",
      " 480/2256 [=====>........................] - ETA: 0s - loss: 13.9400 - mean_squared_error: 13.9400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengxd\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256/2256 [==============================] - 1s 435us/step - loss: 14.9358 - mean_squared_error: 14.9358 - val_loss: 13.8534 - val_mean_squared_error: 13.8534\n",
      "Epoch 3/20\n",
      "2256/2256 [==============================] - 1s 444us/step - loss: 11.6265 - mean_squared_error: 11.6265 - val_loss: 12.6491 - val_mean_squared_error: 12.6491\n",
      "Epoch 4/20\n",
      "2256/2256 [==============================] - 1s 430us/step - loss: 9.4548 - mean_squared_error: 9.4548 - val_loss: 9.7723 - val_mean_squared_error: 9.7723\n",
      "Epoch 5/20\n",
      "2256/2256 [==============================] - 1s 430us/step - loss: 7.9652 - mean_squared_error: 7.9652 - val_loss: 9.2184 - val_mean_squared_error: 9.2184\n",
      "Epoch 6/20\n",
      "2256/2256 [==============================] - 1s 437us/step - loss: 7.0529 - mean_squared_error: 7.0529 - val_loss: 8.0432 - val_mean_squared_error: 8.0432\n",
      "Epoch 7/20\n",
      "2256/2256 [==============================] - 1s 441us/step - loss: 6.3581 - mean_squared_error: 6.3581 - val_loss: 7.4545 - val_mean_squared_error: 7.4545\n",
      "Epoch 8/20\n",
      "2256/2256 [==============================] - 1s 425us/step - loss: 5.9366 - mean_squared_error: 5.9366 - val_loss: 7.2573 - val_mean_squared_error: 7.2573\n",
      "Epoch 9/20\n",
      "2256/2256 [==============================] - 1s 435us/step - loss: 5.5979 - mean_squared_error: 5.5979 - val_loss: 6.8542 - val_mean_squared_error: 6.8542\n",
      "Epoch 10/20\n",
      "2256/2256 [==============================] - 1s 431us/step - loss: 5.3420 - mean_squared_error: 5.3420 - val_loss: 6.6096 - val_mean_squared_error: 6.6096\n",
      "Epoch 11/20\n",
      "2256/2256 [==============================] - 1s 430us/step - loss: 5.0591 - mean_squared_error: 5.0591 - val_loss: 6.4610 - val_mean_squared_error: 6.4610\n",
      "Epoch 12/20\n",
      "2256/2256 [==============================] - 1s 393us/step - loss: 4.8857 - mean_squared_error: 4.8857 - val_loss: 6.2508 - val_mean_squared_error: 6.2508\n",
      "Epoch 13/20\n",
      "2256/2256 [==============================] - 1s 393us/step - loss: 4.7276 - mean_squared_error: 4.7276 - val_loss: 6.0392 - val_mean_squared_error: 6.0392\n",
      "Epoch 14/20\n",
      "2256/2256 [==============================] - 1s 390us/step - loss: 4.5711 - mean_squared_error: 4.5711 - val_loss: 5.9277 - val_mean_squared_error: 5.9277\n",
      "Epoch 15/20\n",
      "2256/2256 [==============================] - 1s 401us/step - loss: 4.4282 - mean_squared_error: 4.4282 - val_loss: 5.8450 - val_mean_squared_error: 5.8450\n",
      "Epoch 16/20\n",
      "2256/2256 [==============================] - 1s 394us/step - loss: 4.2933 - mean_squared_error: 4.2933 - val_loss: 5.6751 - val_mean_squared_error: 5.6751\n",
      "Epoch 17/20\n",
      "2256/2256 [==============================] - 1s 407us/step - loss: 4.1749 - mean_squared_error: 4.1749 - val_loss: 5.5810 - val_mean_squared_error: 5.5810\n",
      "Epoch 18/20\n",
      "2256/2256 [==============================] - 1s 394us/step - loss: 4.0743 - mean_squared_error: 4.0743 - val_loss: 5.5201 - val_mean_squared_error: 5.5201\n",
      "Epoch 19/20\n",
      "2256/2256 [==============================] - 1s 395us/step - loss: 3.9875 - mean_squared_error: 3.9875 - val_loss: 5.4388 - val_mean_squared_error: 5.4388\n",
      "Epoch 20/20\n",
      "2256/2256 [==============================] - 1s 396us/step - loss: 3.8849 - mean_squared_error: 3.8849 - val_loss: 5.4646 - val_mean_squared_error: 5.4646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengxd\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "C:\\Users\\fengxd\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                2576      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,593\n",
      "Trainable params: 2,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 2s 725us/step - loss: 2.4715 - mean_squared_error: 2.4715 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "Test score: 1.1119917433701194\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 31us/step - loss: 0.9419 - mean_squared_error: 0.9419 - val_loss: 0.9332 - val_mean_squared_error: 0.9332\n",
      "Test score: 0.9578262518158117\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 27us/step - loss: 0.8925 - mean_squared_error: 0.8925 - val_loss: 0.8906 - val_mean_squared_error: 0.8906\n",
      "Test score: 0.9813821394744621\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 33us/step - loss: 0.8634 - mean_squared_error: 0.8634 - val_loss: 0.8911 - val_mean_squared_error: 0.8911\n",
      "Test score: 0.9757930376021264\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 30us/step - loss: 0.8538 - mean_squared_error: 0.8538 - val_loss: 0.8926 - val_mean_squared_error: 0.8926\n",
      "Test score: 0.9687762334480049\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 25us/step - loss: 0.8480 - mean_squared_error: 0.8480 - val_loss: 0.9128 - val_mean_squared_error: 0.9128\n",
      "Test score: 1.0083128591501935\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 29us/step - loss: 0.8359 - mean_squared_error: 0.8359 - val_loss: 0.8847 - val_mean_squared_error: 0.8847\n",
      "Test score: 0.9172571734612033\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 31us/step - loss: 0.8395 - mean_squared_error: 0.8395 - val_loss: 0.8641 - val_mean_squared_error: 0.8641\n",
      "Test score: 0.8765306581374774\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 27us/step - loss: 0.8298 - mean_squared_error: 0.8298 - val_loss: 1.0596 - val_mean_squared_error: 1.0596\n",
      "Test score: 1.2373568439088747\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 28us/step - loss: 0.8204 - mean_squared_error: 0.8204 - val_loss: 0.8707 - val_mean_squared_error: 0.8707\n",
      "Test score: 0.877198660842627\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 26us/step - loss: 0.8277 - mean_squared_error: 0.8277 - val_loss: 0.8600 - val_mean_squared_error: 0.8600\n",
      "Test score: 0.9075987459956736\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 28us/step - loss: 0.8136 - mean_squared_error: 0.8136 - val_loss: 0.8601 - val_mean_squared_error: 0.8601\n",
      "Test score: 0.8769816856206574\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 42us/step - loss: 0.8250 - mean_squared_error: 0.8250 - val_loss: 0.8347 - val_mean_squared_error: 0.8347\n",
      "Test score: 0.8789512387960841\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 33us/step - loss: 0.7986 - mean_squared_error: 0.7986 - val_loss: 0.8494 - val_mean_squared_error: 0.8494\n",
      "Test score: 0.8764334031020139\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 25us/step - loss: 0.8121 - mean_squared_error: 0.8121 - val_loss: 0.8556 - val_mean_squared_error: 0.8556\n",
      "Test score: 0.8701823219255878\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 37us/step - loss: 0.7998 - mean_squared_error: 0.7998 - val_loss: 0.8362 - val_mean_squared_error: 0.8362\n",
      "Test score: 0.8686018051814836\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 33us/step - loss: 0.8212 - mean_squared_error: 0.8212 - val_loss: 0.8367 - val_mean_squared_error: 0.8367\n",
      "Test score: 0.8955054438632467\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 38us/step - loss: 0.7981 - mean_squared_error: 0.7981 - val_loss: 0.8328 - val_mean_squared_error: 0.8328\n",
      "Test score: 0.9187420322781518\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 28us/step - loss: 0.8034 - mean_squared_error: 0.8034 - val_loss: 0.8267 - val_mean_squared_error: 0.8267\n",
      "Test score: 0.8766325569054108\n",
      "Train on 2256 samples, validate on 483 samples\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 0s 30us/step - loss: 0.7970 - mean_squared_error: 0.7970 - val_loss: 0.8282 - val_mean_squared_error: 0.8282\n",
      "Test score: 0.8809157629684385\n"
     ]
    }
   ],
   "source": [
    "## LSTM autoencoder\n",
    "retrunSeq=True\n",
    "input_data = Input((None,INPUT_SIZE))\n",
    "encoder=GRU(units=OUTPUT_SIZE*2,  activation='tanh',return_sequences=retrunSeq, name=\"gru1\")(input_data)\n",
    "encoder=GRU(units=OUTPUT_SIZE,  activation='tanh',return_sequences=retrunSeq, name=\"gru2\")(encoder)\n",
    "encoder_out=Dense(OUTPUT_SIZE,activation='tanh')(encoder)\n",
    "encoder_model = Model(inputs=input_data, outputs=encoder_out)\n",
    "\n",
    "decoder=GRU(units=OUTPUT_SIZE, activation='tanh',return_sequences=retrunSeq,name=\"de_gru1\")(encoder_out)\n",
    "decoder=GRU(units=OUTPUT_SIZE*2,  activation='tanh', return_sequences=retrunSeq, name=\"de_gru2\")(decoder)\n",
    "decoder_out=Dense(INPUT_SIZE,activation='relu')(decoder)\n",
    "autoencoder=Model(input_data,decoder_out)\n",
    " \n",
    "#编译模型\n",
    "autoencoder.compile(loss='mean_squared_error',optimizer='adadelta',metrics=['mse'])\n",
    "autoencoder.summary()  #打印模型\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3,verbose = 1, factor=0.5, min_lr = 0.000001)\n",
    "#训练模型\n",
    "autoencoder.fit(x_train, x_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, x_val), \n",
    "          shuffle=True, verbose=1,callbacks=[learning_rate_reduction])\n",
    "#预测模型\n",
    "encoded_latent_train = encoder_model.predict(x_train)\n",
    "encoded_latent_test = encoder_model.predict(x_test)\n",
    "encoded_latent_val = encoder_model.predict(x_val)\n",
    "if retrunSeq:\n",
    "    encoded_latent_train=encoded_latent_train.reshape(-1,OUTPUT_SIZE*TIME_STEPS)\n",
    "    encoded_latent_test=encoded_latent_test.reshape(-1,OUTPUT_SIZE*TIME_STEPS)\n",
    "    encoded_latent_val=encoded_latent_val.reshape(-1,OUTPUT_SIZE*TIME_STEPS)\n",
    "\n",
    "input_representation = Input(shape=(OUTPUT_SIZE*TIME_STEPS,))\n",
    "latent_vector = Dense(16, activation='relu')(input_representation)\n",
    "preddiction = Dense(1, activation='relu')(latent_vector)\n",
    "model2 = Model(input= input_representation,output=preddiction)\n",
    "#编译\n",
    "model2.compile(loss='mean_squared_error',optimizer='adadelta',metrics=['mse'])\n",
    "model2.summary()  #打印模型\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3,verbose = 1, factor=0.5, min_lr = 0.00001)\n",
    "#训练模型\n",
    "f = open('result_epoch_rnn_ae.csv','w')\n",
    "for epoch in range(epochs):\n",
    "    model2.fit(encoded_latent_train, y_train, batch_size=batch_size, nb_epoch=1, validation_data=(encoded_latent_val, y_val), \n",
    "              shuffle=True, verbose=1,callbacks=[learning_rate_reduction])\n",
    "    test_score = model2.evaluate(encoded_latent_test, y_test, verbose=0)\n",
    "    val_score  = model2.evaluate(encoded_latent_val, y_val, verbose=0)\n",
    "    f.write(str(epoch)+',Test score,'+ str(test_score[0])+',Val_score,'+str(val_score[0])+'\\n')\n",
    "    print('Test score:', test_score[0])\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengxd\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fengxd\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 13s 591us/step - loss: 1.3486 - mean_squared_error: 1.3486 - val_loss: 1.2828 - val_mean_squared_error: 1.2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengxd\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.1862049976200226\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 479us/step - loss: 1.2559 - mean_squared_error: 1.2559 - val_loss: 1.2524 - val_mean_squared_error: 1.2524\n",
      "Test score: 1.2478933780987076\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 476us/step - loss: 1.2486 - mean_squared_error: 1.2486 - val_loss: 1.1736 - val_mean_squared_error: 1.1736\n",
      "Test score: 1.119878930195403\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 492us/step - loss: 1.2394 - mean_squared_error: 1.2394 - val_loss: 1.3421 - val_mean_squared_error: 1.3421\n",
      "Test score: 1.2344725011872235\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 491us/step - loss: 1.2330 - mean_squared_error: 1.2330 - val_loss: 1.2871 - val_mean_squared_error: 1.2871\n",
      "Test score: 1.198561639077816\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 494us/step - loss: 1.2274 - mean_squared_error: 1.2274 - val_loss: 1.1573 - val_mean_squared_error: 1.1573\n",
      "Test score: 1.110097294037121\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 12s 512us/step - loss: 1.2257 - mean_squared_error: 1.2257 - val_loss: 1.2647 - val_mean_squared_error: 1.2647\n",
      "Test score: 1.1718901382070153\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 497us/step - loss: 1.2203 - mean_squared_error: 1.2203 - val_loss: 1.1661 - val_mean_squared_error: 1.1661\n",
      "Test score: 1.1299693316754407\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 495us/step - loss: 1.2179 - mean_squared_error: 1.2179 - val_loss: 1.1704 - val_mean_squared_error: 1.1704\n",
      "Test score: 1.131945347580036\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 501us/step - loss: 1.2170 - mean_squared_error: 1.2170 - val_loss: 1.1854 - val_mean_squared_error: 1.1854\n",
      "Test score: 1.161643409236282\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 504us/step - loss: 1.2158 - mean_squared_error: 1.2158 - val_loss: 1.3116 - val_mean_squared_error: 1.3116\n",
      "Test score: 1.2102571651569345\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 506us/step - loss: 1.2106 - mean_squared_error: 1.2106 - val_loss: 1.2108 - val_mean_squared_error: 1.2108\n",
      "Test score: 1.2085005770292445\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 498us/step - loss: 1.2122 - mean_squared_error: 1.2122 - val_loss: 1.1820 - val_mean_squared_error: 1.1820\n",
      "Test score: 1.1399379949767772\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 493us/step - loss: 1.2085 - mean_squared_error: 1.2085 - val_loss: 1.2654 - val_mean_squared_error: 1.2654\n",
      "Test score: 1.1785298898684349\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 495us/step - loss: 1.2065 - mean_squared_error: 1.2065 - val_loss: 1.2314 - val_mean_squared_error: 1.2314\n",
      "Test score: 1.2326688528330563\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 488us/step - loss: 1.2064 - mean_squared_error: 1.2064 - val_loss: 1.2777 - val_mean_squared_error: 1.2777\n",
      "Test score: 1.1878047927818793\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 488us/step - loss: 1.2038 - mean_squared_error: 1.2038 - val_loss: 1.1868 - val_mean_squared_error: 1.1868\n",
      "Test score: 1.1180478777386342\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 488us/step - loss: 1.2029 - mean_squared_error: 1.2029 - val_loss: 1.1874 - val_mean_squared_error: 1.1874\n",
      "Test score: 1.117400617651456\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 482us/step - loss: 1.2021 - mean_squared_error: 1.2021 - val_loss: 1.1848 - val_mean_squared_error: 1.1848\n",
      "Test score: 1.1502901106098418\n",
      "Train on 22699 samples, validate on 4864 samples\n",
      "Epoch 1/1\n",
      "22699/22699 [==============================] - 11s 492us/step - loss: 1.2020 - mean_squared_error: 1.2020 - val_loss: 1.2178 - val_mean_squared_error: 1.2178\n",
      "Test score: 1.1357321735274613\n"
     ]
    }
   ],
   "source": [
    "## LSTM SelfAttention\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=OUTPUT_SIZE, input_shape=input_shape,return_sequences=True)))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=OUTPUT_SIZE,return_sequences=True)))\n",
    "model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "#model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "model.add(Flatten()) #拉成一维数据\n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='relu')) #全连接层2\n",
    "# model.add(Dense(1, activation='relu')) #全连接层2\n",
    " \n",
    "#编译模型\n",
    "model.compile(loss='mean_squared_error',optimizer='adadelta',metrics=['mse'])\n",
    "#model.summary()  #打印模型\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3,verbose = 1, factor=0.5, min_lr = 0.0000004)\n",
    "#训练模型\n",
    "f = open('result_epoch_rnn_SA.csv','w')\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=1, validation_data=(x_val, y_val), \n",
    "              shuffle=True, verbose=1,callbacks=[learning_rate_reduction])\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    val_score  = model.evaluate(x_val, y_val, verbose=0)\n",
    "    f.write(str(epoch)+',Test score,'+ str(test_score[0])+',Val_score,'+str(val_score[0])+'\\n')\n",
    "    print('Test score:', test_score[0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 10s 496us/step - loss: 1.4462 - mse: 1.4462 - val_loss: 1.5436 - val_mse: 1.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_mse,loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.5030113222088965\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 379us/step - loss: 1.3329 - mse: 1.3329 - val_loss: 1.3620 - val_mse: 1.3620\n",
      "Test score: 1.383026429693588\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 386us/step - loss: 1.3121 - mse: 1.3121 - val_loss: 1.2835 - val_mse: 1.2835\n",
      "Test score: 1.2879266967838272\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 393us/step - loss: 1.3013 - mse: 1.3013 - val_loss: 1.2734 - val_mse: 1.2734\n",
      "Test score: 1.2676718821438453\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 396us/step - loss: 1.2941 - mse: 1.2941 - val_loss: 1.2952 - val_mse: 1.2952\n",
      "Test score: 1.2968573546191804\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 9s 430us/step - loss: 1.2908 - mse: 1.2908 - val_loss: 1.2789 - val_mse: 1.2789\n",
      "Test score: 1.2739709472742358\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 400us/step - loss: 1.2858 - mse: 1.2858 - val_loss: 1.2936 - val_mse: 1.2936\n",
      "Test score: 1.2861634920756224\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 9s 425us/step - loss: 1.2825 - mse: 1.2825 - val_loss: 1.2816 - val_mse: 1.2816\n",
      "Test score: 1.28589440412726\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 8s 401us/step - loss: 1.2773 - mse: 1.2773 - val_loss: 1.2773 - val_mse: 1.2773\n",
      "Test score: 1.2873574649297383\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 9s 420us/step - loss: 1.2772 - mse: 1.2772 - val_loss: 1.2685 - val_mse: 1.2685\n",
      "Test score: 1.2734125062794803\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 9s 410us/step - loss: 1.2740 - mse: 1.2740 - val_loss: 1.2861 - val_mse: 1.2861\n",
      "Test score: 1.2906514058352174\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "16416/21015 [======================>.......] - ETA: 1s - loss: 1.2618 - mse: 1.2618"
     ]
    }
   ],
   "source": [
    "## LSTM Bi\n",
    "model = Sequential()\n",
    "#model.add(keras.layers.Embedding(input_dim=INPUT_SIZE, output_dim=16,mask_zero=True))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=OUTPUT_SIZE, input_shape=input_shape,return_sequences=True)))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=OUTPUT_SIZE,return_sequences=True)))\n",
    "\n",
    "model.add(Flatten()) #拉成一维数据\n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(1, activation='relu')) #全连接层2\n",
    "# model.add(Dense(1, activation='relu')) #全连接层2\n",
    " \n",
    "#编译模型\n",
    "model.compile(loss='mean_squared_error',optimizer='adadelta',metrics=['mse'])\n",
    "#model.summary()  #打印模型\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3,verbose = 1, factor=0.5, min_lr = 0.00000001)\n",
    "#训练模型\n",
    "f = open(datasetName+'result_epoch_rnn_bi.csv','w')\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=1, validation_data=(x_val, y_val), \n",
    "              shuffle=True, verbose=1,callbacks=[learning_rate_reduction])\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    val_score  = model.evaluate(x_val, y_val, verbose=0)\n",
    "    f.write(str(epoch)+',Test score,'+ str(test_score[0])+',Val_score,'+str(val_score[0])+'\\n')\n",
    "    print('Test score:', test_score[0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 48us/step - loss: 2.3459 - mse: 2.3459 - val_loss: 1.5719 - val_mse: 1.5719\n",
      "Test score: 1.615163203508504\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      " 3328/21015 [===>..........................] - ETA: 0s - loss: 1.6000 - mse: 1.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_mse,loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21015/21015 [==============================] - 1s 34us/step - loss: 1.6155 - mse: 1.6155 - val_loss: 1.4943 - val_mse: 1.4943\n",
      "Test score: 1.4662687530405132\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 34us/step - loss: 1.4961 - mse: 1.4961 - val_loss: 1.3866 - val_mse: 1.3866\n",
      "Test score: 1.4101997326330595\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - ETA: 0s - loss: 1.4666 - mse: 1.466 - 1s 34us/step - loss: 1.4607 - mse: 1.4607 - val_loss: 1.4984 - val_mse: 1.4984\n",
      "Test score: 1.5859291489929157\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 36us/step - loss: 1.4229 - mse: 1.4229 - val_loss: 1.3904 - val_mse: 1.3904\n",
      "Test score: 1.405143424840092\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 35us/step - loss: 1.4082 - mse: 1.4082 - val_loss: 1.3500 - val_mse: 1.3500\n",
      "Test score: 1.3595429063729731\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 34us/step - loss: 1.3724 - mse: 1.3724 - val_loss: 1.3829 - val_mse: 1.3829\n",
      "Test score: 1.3763139998808975\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 37us/step - loss: 1.3629 - mse: 1.3629 - val_loss: 1.3793 - val_mse: 1.3793\n",
      "Test score: 1.3720453136509736\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 34us/step - loss: 1.3519 - mse: 1.3519 - val_loss: 1.3305 - val_mse: 1.3305\n",
      "Test score: 1.3581375935692075\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 35us/step - loss: 1.3298 - mse: 1.3298 - val_loss: 1.3969 - val_mse: 1.3969\n",
      "Test score: 1.451331578193512\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 34us/step - loss: 1.3302 - mse: 1.3302 - val_loss: 1.3727 - val_mse: 1.3727\n",
      "Test score: 1.4142942289549352\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 34us/step - loss: 1.3268 - mse: 1.3268 - val_loss: 1.3203 - val_mse: 1.3203\n",
      "Test score: 1.3302497015349901\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 39us/step - loss: 1.3132 - mse: 1.3132 - val_loss: 1.3308 - val_mse: 1.3308\n",
      "Test score: 1.3262573985605703\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 38us/step - loss: 1.3160 - mse: 1.3160 - val_loss: 1.3321 - val_mse: 1.3321\n",
      "Test score: 1.3542356640258766\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 34us/step - loss: 1.3057 - mse: 1.3057 - val_loss: 1.3342 - val_mse: 1.3342\n",
      "Test score: 1.3525043125488916\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 35us/step - loss: 1.3009 - mse: 1.3009 - val_loss: 1.3168 - val_mse: 1.3168\n",
      "Test score: 1.3294431734470038\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 35us/step - loss: 1.3017 - mse: 1.3017 - val_loss: 1.3202 - val_mse: 1.3202\n",
      "Test score: 1.3274590789271383\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 38us/step - loss: 1.2900 - mse: 1.2900 - val_loss: 1.3462 - val_mse: 1.3462\n",
      "Test score: 1.3448895597397104\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 36us/step - loss: 1.2908 - mse: 1.2908 - val_loss: 1.3395 - val_mse: 1.3395\n",
      "Test score: 1.3436721562579454\n",
      "Train on 21015 samples, validate on 4476 samples\n",
      "Epoch 1/1\n",
      "21015/21015 [==============================] - 1s 36us/step - loss: 1.2841 - mse: 1.2841 - val_loss: 1.3255 - val_mse: 1.3255\n",
      "Test score: 1.347464566654224\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                7200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 7,473\n",
      "Trainable params: 7,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## mlp\n",
    "model = Sequential()\n",
    "model.add(Flatten()) #拉成一维数据\n",
    "model.add(Dense(32, activation='relu')) \n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='relu')) #全连接层2\n",
    "# model.add(Dense(1, activation='relu')) #全连接层2\n",
    " \n",
    "#编译模型\n",
    "model.compile(loss='mean_squared_error',optimizer='adadelta',metrics=['mse'])\n",
    "#model.summary()  #打印模型\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3,verbose = 1, factor=0.5, min_lr = 0.000000005)\n",
    "#训练模型\n",
    "f = open(datasetName+'result_epoch_mlp.csv','w')\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=1, validation_data=(x_val, y_val), \n",
    "              shuffle=True, verbose=1,callbacks=[learning_rate_reduction])\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    val_score  = model.evaluate(x_val, y_val, verbose=0)\n",
    "    f.write(str(epoch)+',Test score,'+ str(test_score[0])+',Val_score,'+str(val_score[0])+'\\n')\n",
    "    print('Test score:', test_score[0])\n",
    "f.close()\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation time 94607999\n",
      "the number of time interval: 6\n",
      "time interval: 15768000\n"
     ]
    }
   ],
   "source": [
    "import config_hep as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.022367813028454"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
