{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation time 3599\n",
      "the number of time interval: 6\n",
      "time interval: 600\n"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/marsjhao/article/details/68490105 https://blog.csdn.net/u014281392/article/details/77103747\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "np.random.seed(355)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dropout, Bidirectional,Activation,Flatten,GRU,LSTM\n",
    "from keras.layers import Dense, Input, TimeDistributed,RepeatVector\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "import math\n",
    "import time\n",
    "import config_seq_hep as cf\n",
    "import six.moves.cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局变量\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "CELL_SIZE=32\n",
    "OUTPUT_SIZE=16\n",
    "output_length = len(cf.pre_times)\n",
    "# input image dimensions\n",
    "TIME_STEPS = cf.n_time_interval\n",
    "INPUT_SIZE = len(cf.degree_interval_list)+1\n",
    "input_shape = (TIME_STEPS, INPUT_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29529, 6, 10)\n",
      "(29529, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "id_train, x_train, L, y_train, sz_train, time_train, vocabulary_size = pickle.load(open(cf.train_pkl, 'rb'))\n",
    "id_test, x_test, L_test, y_test, sz_test, time_test, _ = pickle.load(open(cf.test_pkl, 'rb'))\n",
    "id_val, x_val, L_val, y_val, sz_val, time_val, _ = pickle.load(open(cf.val_pkl, 'rb'))\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = np.array(x_train[i])\n",
    "    y_train[i] = np.array(y_train[i])\n",
    "for i in range(len(x_val)):\n",
    "    x_val[i] = np.array(x_val[i])\n",
    "    y_val[i] = np.array(y_val[i])\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i] = np.array(x_test[i])\n",
    "    y_test[i] = np.array(y_test[i])\n",
    "x_val = np.array(x_val)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_val = np.array(y_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_val=y_val.reshape(y_val.shape[0],output_length,1)\n",
    "y_train=y_train.reshape(y_train.shape[0],output_length,1)\n",
    "y_test=y_test.reshape(y_test.shape[0],output_length,1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "# x_train = x_train.reshape(x_train.shape[0], TIME_STEPS, INPUT_SIZE, 1)\n",
    "# x_test = x_test.reshape(x_test.shape[0], TIME_STEPS, INPUT_SIZE, 1)\n",
    "# x_val = x_val.reshape(x_val.shape[0], TIME_STEPS, INPUT_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_compute(y_pred,y):\n",
    "    y_pred = y_pred[:,-1,0]\n",
    "    y = y[:,-1,0]\n",
    "    mse = np.mean(np.power(y-y_pred,2))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_9 (Bidirection (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 8, 64)             9408      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8, 16)             1040      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 8, 1)              17        \n",
      "=================================================================\n",
      "Total params: 19,761\n",
      "Trainable params: 19,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 10s 330us/step - loss: 2.3459 - mse: 2.3459 - val_loss: 1.9710 - val_mse: 1.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengx\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_mse,loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 2.0941842257991605 \t Val_score 2.2491521145626883\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 9s 290us/step - loss: 1.8351 - mse: 1.8351 - val_loss: 1.9166 - val_mse: 1.9166\n",
      "Test score: 2.030105534017773 \t Val_score 2.1877624989814857\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 8s 286us/step - loss: 1.8065 - mse: 1.8065 - val_loss: 1.9370 - val_mse: 1.9370\n",
      "Test score: 2.047245500293961 \t Val_score 2.2167919367412874\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 11s 376us/step - loss: 1.7886 - mse: 1.7886 - val_loss: 1.9031 - val_mse: 1.9031\n",
      "Test score: 2.039233059227877 \t Val_score 2.166288080812645\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 12s 419us/step - loss: 1.7707 - mse: 1.7707 - val_loss: 1.9735 - val_mse: 1.9735\n",
      "Test score: 2.058899561360073 \t Val_score 2.2230604804939986\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 13s 443us/step - loss: 1.7645 - mse: 1.7645 - val_loss: 1.8666 - val_mse: 1.8666\n",
      "Test score: 1.9928260205864685 \t Val_score 2.1189300583318573\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 10s 348us/step - loss: 1.7614 - mse: 1.7614 - val_loss: 1.8683 - val_mse: 1.8683\n",
      "Test score: 2.0064446204763224 \t Val_score 2.115743612560214\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 9s 305us/step - loss: 1.7512 - mse: 1.7512 - val_loss: 1.8966 - val_mse: 1.8966\n",
      "Test score: 2.0162511196286914 \t Val_score 2.159506294238696\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 11s 385us/step - loss: 1.7376 - mse: 1.7376 - val_loss: 1.9226 - val_mse: 1.9226\n",
      "Test score: 2.033127009991988 \t Val_score 2.1795695224994835\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 8s 287us/step - loss: 1.7343 - mse: 1.7343 - val_loss: 1.8945 - val_mse: 1.8945\n",
      "Test score: 2.0005981568941027 \t Val_score 2.132866706778236\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 8s 287us/step - loss: 1.7238 - mse: 1.7238 - val_loss: 1.8661 - val_mse: 1.8661\n",
      "Test score: 1.9728365157607577 \t Val_score 2.114160931621757\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 9s 308us/step - loss: 1.7210 - mse: 1.7210 - val_loss: 1.8770 - val_mse: 1.8770\n",
      "Test score: 1.9872468349806431 \t Val_score 2.1354037464037763\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 10s 342us/step - loss: 1.7141 - mse: 1.7141 - val_loss: 1.8479 - val_mse: 1.8479\n",
      "Test score: 1.9941011789881562 \t Val_score 2.0964527506582673\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 9s 302us/step - loss: 1.7021 - mse: 1.7021 - val_loss: 1.8594 - val_mse: 1.8594\n",
      "Test score: 1.9589959309746048 \t Val_score 2.1060564931199504\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 8s 280us/step - loss: 1.7024 - mse: 1.7024 - val_loss: 1.8709 - val_mse: 1.8709\n",
      "Test score: 1.9724771977491278 \t Val_score 2.1170862570415996\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 8s 277us/step - loss: 1.6986 - mse: 1.6986 - val_loss: 1.8519 - val_mse: 1.8519\n",
      "Test score: 1.9861340063547686 \t Val_score 2.09861923975687\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 9s 298us/step - loss: 1.6924 - mse: 1.6924 - val_loss: 1.8950 - val_mse: 1.8950\n",
      "Test score: 1.9925921337963373 \t Val_score 2.1420359016224966\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 9s 298us/step - loss: 1.6885 - mse: 1.6885 - val_loss: 1.9030 - val_mse: 1.9030\n",
      "Test score: 1.9819942429231034 \t Val_score 2.150014357331621\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 10s 329us/step - loss: 1.6796 - mse: 1.6796 - val_loss: 1.8635 - val_mse: 1.8635\n",
      "Test score: 1.9884837664500958 \t Val_score 2.1147740477032375\n",
      "Train on 29529 samples, validate on 6327 samples\n",
      "Epoch 1/1\n",
      "29529/29529 [==============================] - 10s 347us/step - loss: 1.6710 - mse: 1.6710 - val_loss: 1.8920 - val_mse: 1.8920\n",
      "Test score: 2.0201493512679893 \t Val_score 2.135079592954361\n"
     ]
    }
   ],
   "source": [
    "## LSTM Seq2Seq\n",
    "def seq2seq_model(input_length,output_sequence_length):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(32, return_sequences = False)))\n",
    "    model.add(Dense(16, activation=\"tanh\"))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(32, return_sequences = True)))\n",
    "    model.add(Dense(16, activation=\"tanh\"))\n",
    "    model.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "    model.compile(loss='mean_squared_error',optimizer=Adam(1e-3),metrics=['mse'])\n",
    "    model.build((None,input_length,INPUT_SIZE))\n",
    "    model.summary()\n",
    "    return model\n",
    "model = seq2seq_model(x_train.shape[1],y_train.shape[1])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3,verbose = 1, factor=0.5, min_lr = 0.00001)\n",
    "#训练模型\n",
    "f = open('result_epoch_seq2seq.csv','w')\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=1, validation_data=(x_val, y_val), \n",
    "              shuffle=True, verbose=1,callbacks=[learning_rate_reduction])\n",
    "    #score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    y_test_predic = model.predict(x_test)\n",
    "    test_score = mse_compute(y_test_predic,y_test)\n",
    "    y_val_predic = model.predict(x_val)\n",
    "    val_score = mse_compute(y_val_predic,y_val)\n",
    "    print('Test score:', test_score,'\\t','Val_score',val_score)\n",
    "    f.write(str(epoch)+',Test score,'+ str(test_score[0])+',Val_score,'+str(val_score[0])+'\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.6536562992570447\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_test_pre = model.predict(x_test)\n",
    "print('Test score:', score[0])\n",
    "f = open('result_test_seq2seq.csv','w')\n",
    "for i in range (len(y_test)):\n",
    "    f.write(str(y_test[i,-1,0])+','+str(y_test_pre[i,-1,0])+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.7871284]\n",
      " [5.416479 ]\n",
      " [5.7073374]\n",
      " [5.8398314]\n",
      " [5.9066963]\n",
      " [5.9464417]\n",
      " [5.9948688]\n",
      " [6.089055 ]]\n",
      "[[5.67242534]\n",
      " [5.83289001]\n",
      " [5.83289001]\n",
      " [5.857981  ]\n",
      " [5.857981  ]\n",
      " [5.9068906 ]\n",
      " [5.93073734]\n",
      " [5.93073734]]\n",
      "1.8775853188032454\n"
     ]
    }
   ],
   "source": [
    "y_train_predic= model.predict(x_train)\n",
    "train_score= mse_compute(y_train_predic,y_train)\n",
    "print (y_train_predic[358])\n",
    "print (y_train[358])\n",
    "print (train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
